# OpenAI Local Proxy Environment Variables
# Copy this file to .env and customize as needed

# Backend Configuration
BACKEND_URL=http://10.50.10.14:1234
BACKEND_TIMEOUT=300

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
SERVER_WORKERS=1

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=text
LOG_REQUEST_BODY=false
LOG_RESPONSE_BODY=false

# Authentication (optional)
AUTH_ENABLED=false
# Comma-separated list of valid API keys
# AUTH_VALID_KEYS=sk-local-key1,sk-local-key2

# Model Configuration
DEFAULT_MODEL=llama-3.1-instruct-13b

# CORS
CORS_ENABLED=true
# Comma-separated list of allowed origins
CORS_ORIGINS=*

# Features
ENABLE_STREAMING=true
ENABLE_EMBEDDINGS=true
ENABLE_METRICS=false
